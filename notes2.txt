use anyhow;
use clap::{Parser, Subcommand};
use duckdb::Connection;
use onnxruntime::{environment::Environment, GraphOptimizationLevel};

/// CLI application for indexing and searching documents
#[derive(Parser, Debug)]
#[command(
    name = "searche",
    version = "0.1.0",
    author = "yusufsarigoz@gmail.com",
    about = "Index and search your documents, and serve it if you wish",
    subcommand_required = true,
    arg_required_else_help = true
)]
struct Cli {
    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand, Debug)]
enum Commands {
    /// Index documents
    Index {
        /// Path to files to index
        #[arg(required = true, num_args(1..), action = clap::ArgAction::Append)]
        files: Vec<String>,

        /// name of the collection to be created
        #[arg(short, long, required = true)]
        collection_name: String,

        /// Model to create embeddings
        #[arg(short, long, default_value = "bge-m3")]
        model: String,

        /// Enable verbose output
        #[arg(short, long, action = clap::ArgAction::SetTrue)]
        verbose: bool,
    },
}

fn main() -> anyhow::Result<()> {
    let cli = Cli::parse(); // Automatically parses the arguments into the struct

    match &cli.command {
        Commands::Index {
            files,
            collection_name,
            model,
            verbose,
        } => {
            println!("Files: {:?}", files);
            println!("collection name: {collection_name}");
            println!("Model: {model}");
            println!("Verbose: {verbose}");
            let conn = Connection::open("data.db")?;
            let json_file = &files[0];
            let _ = conn.execute_batch(
                format!(
                "CREATE TABLE {collection_name} AS SELECT * FROM read_json_auto('{json_file}');"
            )
                .as_str(),
            )?;

            // Create ONNX Runtime environment
            let environment = Environment::builder()
                .with_name("embedder")
                .with_log_level(onnxruntime::LoggingLevel::Warning)
                .build()?;
            // Load the model
            let _ = environment
                .new_session_builder()?
                .with_optimization_level(GraphOptimizationLevel::All)?
                .with_model_from_file(model.as_str())?;

            println!("ONNX model loaded successfully!");
        }
    }

    Ok(())
}
